{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ionosphere data problem assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6YsxxiB1LThkBqDMFZf+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammad19/DL_1Assignment/blob/main/ionosphere_data_problem_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "we_lUzXPD0I8",
        "outputId": "fd63cb31-d844-44e8-ce47-8c8894b9c0e7"
      },
      "source": [
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "import tensorflow as tf\n",
        "df = read_csv('ionosphere_data.csv')\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0         1         0   0.99539  ...    0.18641   -0.45300      g\n",
              "1         1         0   1.00000  ...   -0.13738   -0.02447      b\n",
              "2         1         0   1.00000  ...    0.56045   -0.38238      g\n",
              "3         1         0   1.00000  ...   -0.32382    1.00000      b\n",
              "4         1         0   1.00000  ...   -0.04608   -0.65697      g\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyCXpB_7PA8U",
        "outputId": "3a652dfb-54f0-4474-fe0e-ce90d667c846"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuaRA55JPGOz",
        "outputId": "e58c57e6-3bee-48a3-d401-98ddd162e36d"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1     0\n",
              "feature2     0\n",
              "feature3     0\n",
              "feature4     0\n",
              "feature5     0\n",
              "feature6     0\n",
              "feature7     0\n",
              "feature8     0\n",
              "feature9     0\n",
              "feature10    0\n",
              "feature11    0\n",
              "feature12    0\n",
              "feature13    0\n",
              "feature14    0\n",
              "feature15    0\n",
              "feature16    0\n",
              "feature17    0\n",
              "feature18    0\n",
              "feature19    0\n",
              "feature20    0\n",
              "feature21    0\n",
              "feature22    0\n",
              "feature23    0\n",
              "feature24    0\n",
              "feature25    0\n",
              "feature26    0\n",
              "feature27    0\n",
              "feature28    0\n",
              "feature29    0\n",
              "feature30    0\n",
              "feature31    0\n",
              "feature32    0\n",
              "feature33    0\n",
              "feature34    0\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc1c_6CCPVF1",
        "outputId": "c09e1b37-146e-41c3-8fa9-cb4f15451669"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1       int64\n",
              "feature2       int64\n",
              "feature3     float64\n",
              "feature4     float64\n",
              "feature5     float64\n",
              "feature6     float64\n",
              "feature7     float64\n",
              "feature8     float64\n",
              "feature9     float64\n",
              "feature10    float64\n",
              "feature11    float64\n",
              "feature12    float64\n",
              "feature13    float64\n",
              "feature14    float64\n",
              "feature15    float64\n",
              "feature16    float64\n",
              "feature17    float64\n",
              "feature18    float64\n",
              "feature19    float64\n",
              "feature20    float64\n",
              "feature21    float64\n",
              "feature22    float64\n",
              "feature23    float64\n",
              "feature24    float64\n",
              "feature25    float64\n",
              "feature26    float64\n",
              "feature27    float64\n",
              "feature28    float64\n",
              "feature29    float64\n",
              "feature30    float64\n",
              "feature31    float64\n",
              "feature32    float64\n",
              "feature33    float64\n",
              "feature34    float64\n",
              "label         object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYC5ZEROOrHT",
        "outputId": "1c48819e-4a64-4356-fc6c-8f652a4a1b1d"
      },
      "source": [
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "X = X.astype('float32')\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "n_features = X.shape[1]\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "#x_val = X_train[:35]\n",
        "#partial_x_train = X_train[35:]\n",
        "#y_val = y[:35]\n",
        "#partial_y_train = y[35:]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "#model.add(tf.keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  \n",
        "history = model.fit(X_train, y_train,epochs=100,batch_size=32)\n",
        "#history = model.fit(partial_x_train,partial_y_train,epochs=100,batch_size=32,validation_data=(x_val, y_val))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235\n",
            "116\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.5655\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.5774\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6249\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.5620\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.5951\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.6749\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6786\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7240\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7291\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7706\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7563\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7623\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7797\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7364\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8361\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.8126\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7973\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8002\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8482\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.9002\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8828\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8808\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.9008\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8789\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8920\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.9150\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.9096\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.9018\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.9199\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.9317\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.9087\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3090 - accuracy: 0.9319\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.9304\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.9471\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.9525\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.9253\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.9406\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.9433\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.9357\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.9512\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9729\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.9342\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9451\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.9291\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.9370\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9483\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.9472\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9554\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9480\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9303\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9645\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9438\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.9385\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9598\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9451\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9338\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9560\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9544\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9649\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9462\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9444\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9479\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9398\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9358\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9484\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.9486\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9572\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9372\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1698 - accuracy: 0.9400\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9373\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9557\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9506\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9486\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9617\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9541\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9644\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9511\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9542\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9508\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9364\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9552\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9611\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9492\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9584\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9546\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9520\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9554\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9496\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9503\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9596\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9617\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9670\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9469\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9705\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9764\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9664\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9728\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9664\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKVZuYz0S2lQ",
        "outputId": "494d7b07-3140-43a0-93c2-dbd32b2d7303"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "#model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0, validation_data=(X_test,y_test))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  \n",
        "history = model.fit(X_train, y_train,epochs=200,batch_size=32)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6595\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.7223\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7490\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8082\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7958\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7915\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.8241\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8457\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8575\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8665\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8989\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8892\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.9061\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9105\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.8923\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.9250\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9273\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9162\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9373\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9408\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9368\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9526\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9674\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9649\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9824\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9856\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9654\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9754\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9665\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9718\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9926\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9828\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9824\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9859\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9836\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9917\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9932\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9899\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9976\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0601 - accuracy: 0.9908\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9886\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9888\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9937\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9953\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9836\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9853\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9943\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9944\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9836\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9965\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9921\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9953\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9899\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9938\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9938\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9946\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9958\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9946\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9899\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9865\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9953\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9873\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9899\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9915\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9921\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9873\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9886\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9937\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9886\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9917\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9986\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9958\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9801\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9973\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9973\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9960\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9901\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9901\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9964\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9980\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9935\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9953\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9953\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9964\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9991\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9953\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW5DeI0zIvY3",
        "outputId": "f7d1df9d-e46d-4b89-e90a-121dcfd0809f"
      },
      "source": [
        "results = model.evaluate(X_test, y_test)\n",
        "results"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.9310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32296764850616455, 0.931034505367279]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i1OrMjFF79v",
        "outputId": "37c67846-6371-4ac1-aa0a-476b29b23068"
      },
      "source": [
        "# predict test set\n",
        "yhat = model.predict_classes(X_test)\n",
        "# evaluate predictions\n",
        "score = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.3f' % score)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ceGDv4BU9hI",
        "outputId": "2496f0a5-0f82-4dd9-cb88-a65d83428b1e"
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cBl_UcgmF8Ud",
        "outputId": "6b21935d-779c-4bab-800a-a019272be3d6"
      },
      "source": [
        "# plot learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['accuracy'], label='train1')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}